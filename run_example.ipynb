{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "927c5ec5-02e8-4823-a871-5c2c0652f29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 23:10:08.808623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763881808.817618    2740 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763881808.820672    2740 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1763881808.829107    2740 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763881808.829114    2740 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763881808.829115    2740 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763881808.829116    2740 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import tqdm\n",
    "from tapnet import evaluation_datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4db62e5-123c-4684-98cd-ac75ed476bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video id 0\n",
      "video id 1\n",
      "video id 2\n",
      "video id 3\n",
      "video id 4\n",
      "video id 5\n",
      "video id 6\n",
      "video id 7\n",
      "video id 8\n",
      "video id 9\n",
      "video id 10\n",
      "video id 11\n",
      "video id 12\n",
      "video id 13\n",
      "video id 14\n",
      "video id 15\n",
      "video id 16\n",
      "video id 17\n",
      "video id 18\n",
      "video id 19\n",
      "video id 20\n",
      "video id 21\n",
      "video id 22\n",
      "video id 23\n",
      "video id 24\n",
      "video id 25\n",
      "video id 26\n",
      "video id 27\n",
      "video id 28\n",
      "video id 29\n"
     ]
    }
   ],
   "source": [
    "davis_dataset = evaluation_datasets.create_davis_dataset(\n",
    "    davis_points_path='tapvid_davis/tapvid_davis.pkl',\n",
    "    query_mode='first',\n",
    "    full_resolution=False,\n",
    "    resolution=(256, 256),\n",
    ")\n",
    "\n",
    "cached_dataset = []\n",
    "for j, batch in enumerate(davis_dataset):\n",
    "  cached_dataset.append(batch)\n",
    "  print(\n",
    "      'video id',\n",
    "      j,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99fd2d1-0df5-46eb-a0fc-7df6bfc6fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tapnet.tapnext.tapnext_torch import TAPNext\n",
    "from tapnet.tapnext.tapnext_torch_utils import restore_model_from_jax_checkpoint, tracker_certainty\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f52a535-17c7-42ee-bb0f-f417356575d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval_per_frame(\n",
    "    model,\n",
    "    batch,\n",
    "    get_trackwise_metrics=True,\n",
    "    radius=8,\n",
    "    threshold=0.5,\n",
    "    use_certainty=False,\n",
    "):\n",
    "  with torch.no_grad():\n",
    "    pred_tracks, track_logits, visible_logits, tracking_state = model(\n",
    "        video=batch['video'][:, :1], query_points=batch['query_points']\n",
    "    )\n",
    "    pred_visible = visible_logits > 0\n",
    "    pred_tracks, pred_visible = [pred_tracks.cpu()], [pred_visible.cpu()]\n",
    "    pred_track_logits, pred_visible_logits = [track_logits.cpu()], [\n",
    "        visible_logits.cpu()\n",
    "    ]\n",
    "    for frame in tqdm.tqdm(range(1, batch['video'].shape[1])):\n",
    "      # ***************************************************\n",
    "      # HERE WE RUN POINT TRACKING IN PURELY ONLINE FASHION\n",
    "      # ***************************************************\n",
    "      (\n",
    "          curr_tracks,\n",
    "          curr_track_logits,\n",
    "          curr_visible_logits,\n",
    "          tracking_state,\n",
    "      ) = model(\n",
    "          video=batch['video'][:, frame : frame + 1],\n",
    "          state=tracking_state,\n",
    "      )\n",
    "      curr_visible = curr_visible_logits > 0\n",
    "      # ***************************************************\n",
    "      pred_tracks.append(curr_tracks.cpu())\n",
    "      pred_visible.append(curr_visible.cpu())\n",
    "      pred_track_logits.append(curr_track_logits.cpu())\n",
    "      pred_visible_logits.append(curr_visible_logits.cpu())\n",
    "    tracks = torch.cat(pred_tracks, dim=1).transpose(1, 2)\n",
    "    pred_visible = torch.cat(pred_visible, dim=1).transpose(1, 2)\n",
    "    track_logits = torch.cat(pred_track_logits, dim=1).transpose(1, 2)\n",
    "    visible_logits = torch.cat(pred_visible_logits, dim=1).transpose(1, 2)\n",
    "\n",
    "    pred_certainty = tracker_certainty(tracks, track_logits, radius)\n",
    "    pred_visible_and_certain = (\n",
    "        F.sigmoid(visible_logits) * pred_certainty\n",
    "    ) > threshold\n",
    "\n",
    "    if use_certainty:\n",
    "      occluded = ~(pred_visible_and_certain.squeeze(-1))\n",
    "    else:\n",
    "      occluded = ~(pred_visible.squeeze(-1))\n",
    "\n",
    "  scalars = evaluation_datasets.compute_tapvid_metrics(\n",
    "      batch['query_points'].cpu().numpy(),\n",
    "      batch['occluded'].cpu().numpy(),\n",
    "      batch['target_points'].cpu().numpy(),\n",
    "      occluded.numpy() + 0.0,\n",
    "      tracks.numpy()[..., ::-1],\n",
    "      query_mode='first',\n",
    "      get_trackwise_metrics=get_trackwise_metrics,\n",
    "  )\n",
    "  return (\n",
    "      tracks.numpy()[..., ::-1],\n",
    "      occluded.numpy(),\n",
    "      {k: v.sum(0) for k, v in scalars.items()},\n",
    "  )\n",
    "\n",
    "\n",
    "# @title Function for raw data to the input format {form-width: \"25%\"}\n",
    "def deterministic_eval(cached_dataset, strided=False):\n",
    "  if not strided:\n",
    "    for sample in cached_dataset:\n",
    "      batch = sample['davis'].copy()\n",
    "      # batch['video'] = (batch['video'] + 1) / 2\n",
    "      batch['visible'] = np.logical_not(batch['occluded'])[..., None]\n",
    "      batch['padding'] = np.ones(\n",
    "          batch['query_points'].shape[:2], dtype=np.bool_\n",
    "      )\n",
    "      batch['loss_mask'] = np.ones(\n",
    "          batch['target_points'].shape[:3] + (1,), dtype=np.float32\n",
    "      )\n",
    "      batch['appearance'] = np.ones(\n",
    "          batch['target_points'].shape[:3] + (1,), dtype=np.float32\n",
    "      )\n",
    "\n",
    "      yield batch\n",
    "  else:\n",
    "    for sample in cached_dataset:\n",
    "      batch = sample['davis'].copy()\n",
    "      # batch['video'] = (batch['video'] + 1) / 2\n",
    "      batch['visible'] = np.logical_not(batch['occluded'])[..., None]\n",
    "      batch['padding'] = np.ones(\n",
    "          batch['query_points'].shape[:2], dtype=np.bool_\n",
    "      )\n",
    "      batch['loss_mask'] = np.ones(\n",
    "          batch['target_points'].shape[:3] + (1,), dtype=np.float32\n",
    "      )\n",
    "      batch['appearance'] = np.ones(\n",
    "          batch['target_points'].shape[:3] + (1,), dtype=np.float32\n",
    "      )\n",
    "      backward_batch = {k: v.copy() for k, v in batch.items()}\n",
    "      for key in ['visible', 'appearance', 'loss_mask', 'target_points']:\n",
    "        backward_batch[key] = np.flip(backward_batch[key], axis=2)\n",
    "      backward_batch['video'] = np.flip(backward_batch['video'], axis=1)\n",
    "      backward_queries = (\n",
    "          backward_batch['video'].shape[1]\n",
    "          - backward_batch['query_points'][..., 0]\n",
    "          - 1\n",
    "      )\n",
    "      backward_batch['query_points'][..., 0] = backward_queries\n",
    "      yield batch, backward_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e0325dd-b2f1-4461-8093-954131577b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TAPNext(\n",
       "  (lin_proj): Conv2d(3, 768, kernel_size=(8, 8), stride=(8, 8))\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TRecViTBlock(\n",
       "      (ssm_block): ResidualBlock(\n",
       "        (temporal_pre_norm): RMSNorm()\n",
       "        (recurrent_block): RecurrentBlock(\n",
       "          (linear_y): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_x): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (conv_1d): CausalConv1D()\n",
       "          (rg_lru): RGLRU(\n",
       "            (input_gate): BlockDiagonalLinear()\n",
       "            (a_gate): BlockDiagonalLinear()\n",
       "          )\n",
       "        )\n",
       "        (channel_pre_norm): RMSNorm()\n",
       "        (mlp_block): MLPBlock(\n",
       "          (ffw_up): Einsum()\n",
       "          (ffw_down): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (vit_block): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (visible_head): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): GELU(approximate='none')\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (coordinate_head): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): GELU(approximate='none')\n",
       "    (6): Linear(in_features=256, out_features=512, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TAPNext(image_size=(256, 256))\n",
    "ckpt_path = 'bootstapnext_ckpt.npz'\n",
    "model = restore_model_from_jax_checkpoint(model, ckpt_path)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ade404-9205-4763-8fb9-4669e3990f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 89/89 [00:03<00:00, 23.71it/s]\n",
      "/home/hyz/prog/tapnet/env/lib/python3.10/site-packages/torch/functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████████████████████████████████████████████████████████| 74/74 [00:03<00:00, 23.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 23.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 83/83 [00:03<00:00, 23.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 51/51 [00:02<00:00, 23.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 23.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 23.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 23.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 23.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 99/99 [00:04<00:00, 23.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 80/80 [00:03<00:00, 23.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 78/78 [00:03<00:00, 23.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 103/103 [00:04<00:00, 23.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 77/77 [00:03<00:00, 23.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 79/79 [00:03<00:00, 23.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 89/89 [00:03<00:00, 23.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 23.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 59/59 [00:02<00:00, 23.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 23.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 23.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 23.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 79/79 [00:03<00:00, 23.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 89/89 [00:03<00:00, 23.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 23.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 48/48 [00:02<00:00, 23.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 23.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 78/78 [00:03<00:00, 23.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 23.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 23.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AJ 0.6654442090194489\n",
      "OA 0.9216233752944766\n",
      "PTS 0.7948194112043738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "standard_eval_scalars_list = []\n",
    "preds = []\n",
    "for batch in deterministic_eval(cached_dataset):\n",
    "  batch = {k: torch.from_numpy(v).cuda().float() for k, v in batch.items()}\n",
    "  with torch.amp.autocast('cuda', dtype=torch.float16, enabled=True):\n",
    "    tracks, occluded, scores = run_eval_per_frame(\n",
    "        model, batch, get_trackwise_metrics=False, use_certainty=False\n",
    "    )\n",
    "  standard_eval_scalars_list.append(scores)\n",
    "  preds.append((tracks, occluded))\n",
    "\n",
    "\n",
    "print('')\n",
    "print(\n",
    "    'AJ',\n",
    "    np.mean([\n",
    "        standard_eval_scalars_list[k]['average_jaccard']\n",
    "        for k in range(len(standard_eval_scalars_list))\n",
    "    ]),\n",
    ")\n",
    "print(\n",
    "    'OA',\n",
    "    np.mean([\n",
    "        standard_eval_scalars_list[k]['occlusion_accuracy']\n",
    "        for k in range(len(standard_eval_scalars_list))\n",
    "    ]),\n",
    ")\n",
    "print(\n",
    "    'PTS',\n",
    "    np.mean([\n",
    "        standard_eval_scalars_list[k]['average_pts_within_thresh']\n",
    "        for k in range(len(standard_eval_scalars_list))\n",
    "    ]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54eb24fa-0241-496a-9917-de05b0ec8205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video id 0\n",
      "video id 1\n",
      "video id 2\n",
      "video id 3\n",
      "video id 4\n",
      "video id 5\n",
      "video id 6\n",
      "video id 7\n",
      "video id 8\n",
      "video id 9\n",
      "video id 10\n",
      "video id 11\n",
      "video id 12\n",
      "video id 13\n",
      "video id 14\n",
      "video id 15\n",
      "video id 16\n",
      "video id 17\n",
      "video id 18\n",
      "video id 19\n",
      "video id 20\n",
      "video id 21\n",
      "video id 22\n",
      "video id 23\n",
      "video id 24\n",
      "video id 25\n",
      "video id 26\n",
      "video id 27\n",
      "video id 28\n",
      "video id 29\n"
     ]
    }
   ],
   "source": [
    "davis_dataset_strided = evaluation_datasets.create_davis_dataset(\n",
    "    davis_points_path='tapvid_davis/tapvid_davis.pkl',\n",
    "    query_mode='strided',\n",
    "    full_resolution=False,\n",
    "    resolution=(256, 256),\n",
    ")\n",
    "\n",
    "cached_dataset_strided = []\n",
    "for j, batch in enumerate(davis_dataset_strided):\n",
    "  cached_dataset_strided.append(batch)\n",
    "  print('video id', j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b3c91bf-8184-4e3a-8203-a3906d98dea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 89/89 [00:03<00:00, 22.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 89/89 [00:03<00:00, 22.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 74/74 [00:03<00:00, 22.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 74/74 [00:03<00:00, 22.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 22.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 22.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 83/83 [00:04<00:00, 18.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 83/83 [00:04<00:00, 18.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 51/51 [00:02<00:00, 20.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 51/51 [00:02<00:00, 20.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 22.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 22.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 22.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 21.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 98/98 [00:05<00:00, 18.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 98/98 [00:05<00:00, 18.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 65/65 [00:03<00:00, 19.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 65/65 [00:03<00:00, 19.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 99/99 [00:05<00:00, 19.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 99/99 [00:05<00:00, 19.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 80/80 [00:04<00:00, 18.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 80/80 [00:04<00:00, 18.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 78/78 [00:03<00:00, 20.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 78/78 [00:03<00:00, 20.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 103/103 [00:05<00:00, 19.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 103/103 [00:05<00:00, 19.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 77/77 [00:04<00:00, 18.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 77/77 [00:04<00:00, 18.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 18.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 18.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 89/89 [00:04<00:00, 20.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 89/89 [00:04<00:00, 20.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 22.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 22.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 59/59 [00:02<00:00, 22.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 59/59 [00:02<00:00, 22.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 68/68 [00:03<00:00, 19.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 68/68 [00:03<00:00, 19.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 22.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 22.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 46/46 [00:02<00:00, 19.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 46/46 [00:02<00:00, 19.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 19.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 19.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 79/79 [00:03<00:00, 19.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 79/79 [00:03<00:00, 19.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 89/89 [00:04<00:00, 18.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 89/89 [00:04<00:00, 18.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 20.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 20.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 48/48 [00:02<00:00, 22.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 48/48 [00:02<00:00, 22.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 19.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 19.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 78/78 [00:04<00:00, 18.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 78/78 [00:04<00:00, 18.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 19.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 19.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 19.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 49/49 [00:02<00:00, 19.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AJ 0.7074496686823425\n",
      "OA 0.9184522766619835\n",
      "PTS 0.8315253897988535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "eval_results = list()\n",
    "for vid, (fbatch, bbatch) in enumerate(deterministic_eval(cached_dataset_strided, strided=True)):\n",
    "  fbatch = {k: torch.from_numpy(v).cuda().float() for k, v in fbatch.items()}\n",
    "  bbatch = {k: torch.from_numpy(v.copy()).cuda().float() for k, v in bbatch.items()}\n",
    "  with torch.amp.autocast('cuda', dtype=torch.float16, enabled=True):\n",
    "    ftracks, foccluded, _ = run_eval_per_frame(model, fbatch, get_trackwise_metrics=False, use_certainty=False)\n",
    "    btracks, boccluded, _ = run_eval_per_frame(model, bbatch, get_trackwise_metrics=False, use_certainty=False)\n",
    "  btracks, boccluded = np.flip(btracks, axis=2), np.flip(boccluded, axis=2)\n",
    "  # tracks = [1, q, t, 2]\n",
    "  for q in range(fbatch['query_points'].shape[1]):\n",
    "    t = int((fbatch['query_points'][0, q, 0]).item())\n",
    "    ftracks[0, q, :t] = btracks[0, q, :t]\n",
    "    foccluded[0, q, :t] = boccluded[0, q, :t]\n",
    "  tracks, occluded = ftracks, foccluded\n",
    "  scalars = evaluation_datasets.compute_tapvid_metrics(\n",
    "      cached_dataset_strided[vid]['davis']['query_points'],\n",
    "      cached_dataset_strided[vid]['davis']['occluded'],\n",
    "      cached_dataset_strided[vid]['davis']['target_points'],\n",
    "      occluded + 0.,\n",
    "      tracks,\n",
    "      query_mode='strided',\n",
    "      get_trackwise_metrics=False,\n",
    "  )\n",
    "  eval_results.append(jax.tree.map(lambda x: np.array(np.sum(x, axis=0)), scalars))\n",
    "\n",
    "print('')\n",
    "print(\n",
    "    'AJ',\n",
    "    np.mean([\n",
    "        eval_results[k]['average_jaccard']\n",
    "        for k in range(len(eval_results))\n",
    "    ]),\n",
    ")\n",
    "print(\n",
    "    'OA',\n",
    "    np.mean([\n",
    "        eval_results[k]['occlusion_accuracy']\n",
    "        for k in range(len(eval_results))\n",
    "    ]),\n",
    ")\n",
    "print(\n",
    "    'PTS',\n",
    "    np.mean([\n",
    "        eval_results[k]['average_pts_within_thresh']\n",
    "        for k in range(len(eval_results))\n",
    "    ]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94407c50-1c79-49a0-be4c-93cf81d974f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video id 0\n",
      "video id 1\n",
      "video id 2\n",
      "video id 3\n",
      "video id 4\n",
      "video id 5\n",
      "video id 6\n",
      "video id 7\n",
      "video id 8\n",
      "video id 9\n",
      "video id 10\n",
      "video id 11\n",
      "video id 12\n",
      "video id 13\n",
      "video id 14\n",
      "video id 15\n",
      "video id 16\n",
      "video id 17\n",
      "video id 18\n",
      "video id 19\n",
      "video id 20\n",
      "video id 21\n",
      "video id 22\n",
      "video id 23\n",
      "video id 24\n",
      "video id 25\n",
      "video id 26\n",
      "video id 27\n",
      "video id 28\n",
      "video id 29\n"
     ]
    }
   ],
   "source": [
    "davis_dataset = evaluation_datasets.create_davis_dataset(\n",
    "    davis_points_path='tapvid_davis/tapvid_davis.pkl',\n",
    "    query_mode='first',\n",
    "    full_resolution=False,\n",
    "    resolution=(256, 256),\n",
    ")\n",
    "cached_dataset = []\n",
    "for j, batch in enumerate(davis_dataset):\n",
    "  cached_dataset.append(batch)\n",
    "  print(\n",
    "      'video id',\n",
    "      j,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98c841fc-77b7-4fe5-ad2f-ffc2c822ea2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['video', 'query_points', 'target_points', 'occluded'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cached_dataset)\n",
    "cached_dataset[0]['davis'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5887c1ae-7138-4e0a-9dc5-7863f5e9c332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 89/89 [00:03<00:00, 23.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 90, 2) (1, 5, 90) {'occlusion_accuracy': np.float64(0.9617977528089887), 'pts_within_1': np.float64(0.2966292134831461), 'jaccard_1': np.float64(0.1765498652291105), 'pts_within_2': np.float64(0.6337078651685393), 'jaccard_2': np.float64(0.4696969696969697), 'pts_within_4': np.float64(0.9168539325842696), 'jaccard_4': np.float64(0.814968814968815), 'pts_within_8': np.float64(0.9977528089887641), 'jaccard_8': np.float64(0.9573991031390134), 'pts_within_16': np.float64(1.0), 'jaccard_16': np.float64(0.9617977528089887), 'average_jaccard': np.float64(0.6760825011685795), 'average_pts_within_thresh': np.float64(0.7689887640449438)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "standard_eval_scalars_list = []\n",
    "preds = []\n",
    "\n",
    "\n",
    "for sample in cached_dataset[:1]:\n",
    "  batch = sample['davis'].copy()\n",
    "  # batch['video'] = (batch['video'] + 1) / 2\n",
    "  batch['visible'] = np.logical_not(batch['occluded'])[..., None]\n",
    "  batch['padding'] = np.ones(\n",
    "      batch['query_points'].shape[:2], dtype=np.bool_\n",
    "  )\n",
    "  batch['loss_mask'] = np.ones(\n",
    "      batch['target_points'].shape[:3] + (1,), dtype=np.float32\n",
    "  )\n",
    "  batch['appearance'] = np.ones(\n",
    "      batch['target_points'].shape[:3] + (1,), dtype=np.float32\n",
    "  )\n",
    "\n",
    "  batch = {k: torch.from_numpy(v).cuda().float() for k, v in batch.items()}\n",
    "  with torch.amp.autocast('cuda', dtype=torch.float16, enabled=True):\n",
    "    tracks, occluded, scores = run_eval_per_frame(\n",
    "        model, batch, get_trackwise_metrics=False, use_certainty=False\n",
    "    )\n",
    "    print(tracks.shape, occluded.shape, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86488d6-2db7-43a4-88d4-3b9593ddcf6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
